# Development Workflow Standards

Comprehensive development standards covering commits, file organization, documentation, testing, and code quality.

<rule>
name: development_workflow_standards
description: Development workflow standards including commits, file organization, documentation, testing, and code quality
filters:
  - type: file_extension
    pattern: ".*"
  - type: content
    pattern: "(git|commit|test|doc|header|naming|workflow|co-authored|claude|gpt|ai|assisted)"
  - type: context
    pattern: "(development|workflow|standards|quality|commit|attribution)"
  - type: content
    pattern: "(co-authored|claude|gpt|assisted by|ai helped|generated with)"

actions:
  - type: suggest
    when: "commit_message"
    message: |
      **📝 Commit Message Standards:**

      **Format:**
      ```
      type(scope): description

      [optional body]

      [optional footer]
      ```

      **Types:**
      - `feat`: New feature
      - `fix`: Bug fix
      - `docs`: Documentation changes
      - `style`: Code style changes (formatting, etc.)
      - `refactor`: Code refactoring
      - `test`: Adding or updating tests
      - `chore`: Maintenance tasks

      **Rules:**
      - Use imperative mood ("add" not "added")
      - Keep subject line under 50 characters
      - Start with lowercase letter
      - No period at the end
      - Include scope for better categorization
      - **NEVER include "Co-authored-by" or AI assistant attribution**
      - **NEVER mention Claude, GPT, or any AI assistant in commits**
      - **NEVER use "AI helped" or similar phrases**

      **Examples:**
      ✅ Good:
      ```
      feat: add user authentication system
      fix(api): resolve rate limiting issue
      docs: update API documentation
      test: add unit tests for classification
      ```

      ❌ Bad:
      ```
      git commit -m "fix bug"
      git commit -m "update stuff"
      git commit -m "wip"
      git commit -m "feat: add user auth - Co-authored-by: Claude"
      git commit -m "fix: resolve issue with AI help"
      git commit -m "docs: update README - assisted by GPT"
      ```

  - type: suggest
    when: "ai_attribution_detected"
    message: |
      **🚫 AI Attribution Prohibited:**

      **NEVER include AI assistant attribution in commit messages:**
      - ❌ `Co-authored-by: Claude`
      - ❌ `Co-authored-by: GPT`
      - ❌ `Assisted by AI`
      - ❌ `AI helped with this`
      - ❌ `Generated with Claude`
      - ❌ `Thanks to GPT`

      **Why this matters:**
      - Commit messages should reflect human authorship
      - AI tools are development aids, not co-authors
      - Maintains professional development practices
      - Avoids potential legal/licensing complications

      **Correct approach:**
      - Write commit messages as if you authored the code
      - Focus on what the commit accomplishes
      - Keep attribution for actual human collaborators only

  - type: suggest
    when: "file_organization"
    message: |
      **📁 File Organization Standards:**

      **Directory Structure:**
      ```
      src/                    # Source code
      ├── api/               # API endpoints
      ├── classification/    # Core classification logic
      ├── models/           # Data models
      ├── evaluation/       # RAGAS evaluation
      ├── utils/            # Shared utilities
      └── __init__.py
      
      tests/                 # Test files
      ├── unit/             # Unit tests
      ├── integration/      # Integration tests
      └── conftest.py       # Test configuration
      
      config/               # Configuration files
      ├── *.yaml           # YAML configs
      └── *.json           # JSON configs
      
      scripts/              # Utility scripts
      docs/                 # Documentation
      data/                 # Data files
      ```

      **Naming Conventions:**
      - Files: `snake_case.py`
      - Classes: `PascalCase`
      - Functions: `snake_case`
      - Constants: `UPPER_SNAKE_CASE`
      - Test files: `test_*.py`

  - type: suggest
    when: "file_header"
    message: |
      **📄 File Header Documentation:**

      **Required Header Format:**
      ```python
      """
      Module: path.to.module
      Purpose: What this module does
      Dependencies: List of file dependencies within our system
      
      Brief description of functionality and usage.
      """
      ```

      **Documentation Standards:**
      - **What**: Clear description of module purpose
      - **Why**: Explain why this module exists
      - **How**: Brief explanation of implementation approach
      - **Dependencies**: List files this module depends on
      - **Usage**: Example usage if applicable

      **Function Documentation:**
      ```python
      def process_data(data: Dict) -> List[Result]:
          """
          Process input data and return results.
          
          Args:
              data: Input data dictionary
          
          Returns:
              List of processed results
          
          Dependencies: src/models/data_model.py
          """
      ```

  - type: suggest
    when: "testing_standards"
    message: |
      **🧪 Testing Standards:**

      **Test Organization:**
      - Unit tests in `tests/unit/`
      - Integration tests in `tests/integration/`
      - Test files named `test_*.py`
      - Test classes named `Test*`
      - Test methods named `test_*`

      **Test Structure (AAA Pattern):**
      ```python
      def test_functionality():
          # Arrange - Set up test data
          input_data = create_test_data()
          
          # Act - Execute function
          result = function_under_test(input_data)
          
          # Assert - Verify results
          assert result.expected_value == actual_value
      ```

      **Test Data Management:**
      - Use real data patterns, not dummy data
      - Create realistic test scenarios
      - Use factories for test data generation
      - Avoid hardcoded test values

      **Coverage Requirements:**
      - Minimum 85% code coverage
      - Test all public interfaces
      - Test error conditions
      - Test edge cases

  - type: suggest
    when: "code_quality"
    message: |
      **🔧 Code Quality Standards:**

      **Code Organization:**
      - Single responsibility principle
      - Functions under 20 lines
      - Classes under 200 lines
      - Modules under 500 lines
      - Clear separation of concerns

      **Error Handling:**
      - Use specific exception types
      - Provide meaningful error messages
      - Log errors appropriately
      - Handle edge cases gracefully

      **Performance:**
      - Profile code for bottlenecks
      - Use appropriate data structures
      - Optimize critical paths
      - Monitor memory usage

      **Security:**
      - Validate all inputs
      - Sanitize user data
      - Use secure defaults
      - Follow OWASP guidelines

  - type: suggest
    when: "dummy_data_detected"
    message: |
      **🚫 NO DUMMY DATA POLICY:**

      **NEVER use dummy data in production code:**
      - ❌ `"test_company_123"`
      - ❌ `"dummy_user"`
      - ❌ `"fake_data"`
      - ❌ `"sample_*"`
      - ❌ `"mock_*"`
      - ❌ `"example_*"`

      **ALWAYS use real data patterns:**
      - ✅ Real company IDs from data/raw/company_ids_and_other.csv
      - ✅ Real API responses from actual endpoints
      - ✅ Real classification examples from production
      - ✅ Real configuration values

      **For Testing:**
      - Use Faker library for realistic test data
      - Create test factories that generate realistic data
      - Use actual data samples from production
      - Never hardcode dummy values

      **Data Sources:**
      - Primary: `data/raw/company_ids_and_other.csv`
      - API: Real Finch/Claude API responses
      - Config: Real configuration values from .env
      - Models: Real Pydantic model instances

      **Why this matters:**
      - Ensures code works with real data
      - Prevents bugs from dummy data assumptions
      - Maintains data integrity
      - Improves testing reliability

  - type: suggest
    when: "data_cleanup_needed"
    message: |
      **🧹 Data Cleanup Required:**

      **Remove any dummy data from repository:**
      - Delete files with dummy/test data
      - Replace dummy values with real data patterns
      - Update tests to use real data sources
      - Clean up any hardcoded dummy values

      **Real Data Sources:**
      - Company data: `data/raw/company_ids_and_other.csv`
      - API responses: Real Finch/Claude API calls
      - Configuration: Real .env values
      - Models: Real Pydantic instances

      **Test Data Strategy:**
      - Use Faker for realistic test data generation
      - Create test factories that mirror real data
      - Use actual data samples for integration tests
      - Never commit dummy data to repository
